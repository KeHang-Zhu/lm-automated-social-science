import sys
import json
from typing import List, Dict, Union
import os
import numpy as np
import pandas as pd
from itertools import cycle
import semopy

sys.path.append("../JudeaPearl")
sys.path.append("../LLM")
from Variable import EndogenousVariable, Variable
from StructuralCausalModelBuilder import StructuralCausalModelBuilder
from LLM import LanguageModel, LLMMixin, llm_json_loader


class RaiseCategoricalVariableError(Exception):
    """
    Raised when a categorical variable is encountered.
    """

    def __init__(
        self,
        message="Currently cannot handle any Categorical variables (besides binary)",
    ) -> None:
        super().__init__(message)


class DataCleaner(LLMMixin):
    """
    This class is responsible for analyzing the data.
    It takes in the interaction data, the cleaned data, and the meta data.
    It outputs a latex file with the results of the analysis.
    """

    def __init__(
        self,
        interaction_data: Dict[str, Dict],
        cleaned_data: pd.DataFrame,
        meta_data: Dict,
        LLM=LanguageModel(family="openai", model="gpt-4", temperature=0.1),
    ) -> None:
        # Initialize the Structural Causal Model (SCM)
        self.scm = self._initialize_scm(interaction_data["scm"])
        self.LLM = LLM

        # Extract interaction data and attribute-value mapping from the SCM interaction data
        self.interaction_data = interaction_data["data"]
        self.attribute_value_mapping = interaction_data["attribute_value_mapping"]

        # Extract data frame and metadata from the provided data
        self.raw_df = cleaned_data
        self.meta_data = meta_data
        self.raw_edge_dict = meta_data["scm_structure"]
        # data frame, edge dict with the nominal variables converted to dummy variables (too be converted)
        self.final_df = cleaned_data
        self.final_edge_dict = meta_data["scm_structure"]

        # hold for variable mapping
        self.variable_mapping = {}

    def _initialize_scm(
        self, scm_data: Union[Dict, StructuralCausalModelBuilder]
    ) -> StructuralCausalModelBuilder:
        """
        Initialize the SCM based on the provided interaction data.

        Args:
            interaction_data (Dict[str, Dict]): Data related to SCM interactions.
        """
        serialized_scm = (
            json.dumps(scm_data) if isinstance(scm_data, dict) else scm_data
        )
        scm = StructuralCausalModelBuilder.deserialize(serialized_scm)

        return scm

    def generate_variable_mapping(self, variables, alphakeys=False) -> dict:
        """
        Generate a mapping of variables to their corresponding alphanumeric representations.
        Inputs:
            variables (List[str]): List of variable names.
            alphakeys (bool): Whether to use letters as the alphanumeric representations or shortened versions with an API call. Defaults to False.
            Shortedn versions are generated by calling the LLM API and take more time.

        Returns:
            dict: Dictionary with variable names as keys and alphanumeric representations as values.
        """
        alphabet = cycle("ABCDEFGHIJKLMNOPQRSTUVWXYZ")
        variable_mapping = {}
        interaction_mappings = {}

        for variable in variables:
            # Check if the variable is an interaction (contains '_x_')
            if "_x_" in variable:
                # Split the variable name to find the interacting variables
                interacting_vars = variable.split("_x_")
                # Generate mapping for each interacting variable if not already mapped
                for var in interacting_vars:
                    if var not in variable_mapping:

                        if alphakeys:
                            variable_mapping[var] = next(alphabet)
                        else:
                            variable_mapping[var] = self.get_variable_short_name(var)
                # Combine mappings for the interacting variables
                interaction_mappings[variable] = "_x_".join(
                    [variable_mapping[var] for var in interacting_vars]
                )
            elif variable not in variable_mapping:
                # Map non-interacting variables
                if alphakeys:
                    variable_mapping[variable] = next(alphabet)
                else:
                    variable_mapping[variable] = self.get_variable_short_name(variable)

        # Combine the two mappings
        variable_mapping.update(interaction_mappings)
        return variable_mapping

    def get_variable_short_name(self, variable_name: str) -> str:

        prompt = f"""Please enter an abbreviated name for this variable: {variable_name}.
        The name cannot have any spaces, apostrophes, or special characters - only letters, numbers and underscores.
        You can replace spaces with underscores.
        Here are a few examples:
        For example, if the variable is "the buyer's budget", you can shorten it to "buy_budget".
        None of the words in the variable name can be longer than 7 characters.
        For example, if the variable is the "interviewer's level of friendliness" you should shorten it to "inter_friendly".
        You should have no more than 4 words in the variable name.
        For example, if the variable is "number of cases the Judge has already heard that day" you can shorten it to "judge_cases".
        Don't forget that you can only have letters, numbers and underscores - no apostrophes!
        The entire string must not be more than 12 characters under any circumstances.
        Please respond with a json string with the following format: 
        {{"variable_name": "short_name",
        "explanation": "short explanation of short name"}}.
        """
        raw_output = self.call_llm(prompt)
        output = llm_json_loader(raw_output)
        short_name = output["variable_name"].replace("'", "").replace(" ", "_")
        print(f"short name: {short_name}")
        return short_name

    def __repr__(self) -> str:
        return f"""
                    META DATA: {self.meta_data}
                    DATA FRAME: {self.raw_df}"""

    # NOTE YOU CAN IGNORE THIS FUNCTION SINCE WEARE NOT DOING CATEGORICAL VARIABLES YET
    def nominal_df_builder(self, variable: Variable) -> None:
        """
        Check if any of the columns in the data frame are nominal.
        If they are, convert them to dummy variables.

        Args:
            None
        """
        level_value_dict = self.meta_data["variables"][variable.name][
            "level_value_dict"
        ]
        data_frame, dummy_var_names = self.nominal_to_dummies(
            variable.name, level_value_dict
        )
        # drop the orginal nominal column because it is now represented by dummy variable columns
        self.update_graph_with_dummies(variable.name, dummy_var_names)
        data_frame.drop(variable.name, axis=1)

        return data_frame

    # NOTE YOU CAN IGNORE THIS FUNCTION SINCE WEARE NOT DOING CATEGORICAL VARIABLES YET
    def nominal_to_dummies(
        self, variable_name: str, level_value_dict: Dict
    ) -> pd.DataFrame:
        """
        Converts a column with nominal data to dummy variables in a pandas DataFrame.

        Args:
            variable_name (str): The column name with nominal data.
            level_value_dict (Dict): A dictionary mapping nominal values to their corresponding numerical values.
        """
        # Create a copy of the DataFrame
        data_frame = self.raw_df.copy()

        numerical_values = list(level_value_dict.values())
        nominal_values = list(level_value_dict.keys())

        # Create dummy variables for each possible value
        dummy_var_names = []
        for value in numerical_values:
            # Create a new column for each possible value
            # The column will have 1 if the variable_name has the value, else 0
            index = numerical_values.index(value)
            nominal_value = nominal_values[index]
            # name the column with the nominal value
            dummy_var_name = f"{variable_name}_{nominal_value}"
            dummy_var_names.append(dummy_var_name)
            data_frame[dummy_var_name] = (data_frame[variable_name] == value).astype(
                int
            )

        return data_frame, dummy_var_names

    # NOTE YOU CAN IGNORE THIS FUNCTION SINCE WEARE NOT DOING CATEGORICAL VARIABLES YET
    def update_graph_with_dummies(self, variable_name: str, dummy_var_names: List[str]):
        """
        Updates the graph with new dummy variables created from a nominal variable.

        Args:
            variable_name (str): The name of the nominal variable.
            dummy_var_names (List[str]): List of dummy variable names created from the nominal variable.
        """
        # Update the graph if the nominal variable is a key
        if variable_name in self.final_edge_dict:
            # Retrieve and remove the nominal variable's children
            children = self.final_edge_dict.pop(variable_name)

            # Add each dummy variable with the same children
            for dummy_var in dummy_var_names:
                self.final_edge_dict[dummy_var] = children

    def create_interaction_columns_complete(self, df):
        # Select all columns except the left-most one
        selected_columns = df.columns[1:]

        # Create a set to keep track of created interactions to avoid duplicates
        created_interactions = set()

        # Iterate over all pairs of columns (except the left-most one) to create interaction columns
        for i, col1 in enumerate(selected_columns):
            for col2 in selected_columns[i + 1 :]:
                # Check if the interaction has already been created
                if (col2, col1) not in created_interactions:
                    interaction_column_name = f"{col1}_x_{col2}"
                    df[interaction_column_name] = df[col1] * df[col2]
                    # Add the interaction to the set
                    created_interactions.add((col1, col2))
        return df

    def generate_final_df(self):
        """
        Generates the final data frame for analysis. Also generates the variable mapping and the final edge dictionary.
        """
        for variable in self.scm.variable_dict.values():
            if variable.variable_type == "nominal":
                # blocking for nominal variables for now until we can handle them
                raise RaiseCategoricalVariableError()
                # self.final_df = self.nominal_df_builder(variable)

            # update the mappings everywhere
        self.final_df_interactions = self.create_interaction_columns_complete(
            self.final_df
        )
        self.variable_mapping = self.generate_variable_mapping(
            self.final_df.columns.values
        )

    def save_data(self, path=None):
        """
        Saves the final data frame, variable mapping, and edge dictionary to the specified path.
        """
        # downloading for debugging

        # check if the final_df_interactions has 0 variance in any columns
        # if yes, raise an error

        self.final_df_interactions.to_csv(os.path.join(path, "data.csv"), index=False)
        self.final_mapped_df = self.final_df.rename(columns=self.variable_mapping)
        self.final_mapped_df.to_csv(os.path.join(path, "mapped_data.csv"), index=False)
        # save final mapping dictionary
        with open(os.path.join(path, "final_mapping.json"), "w") as f:
            json.dump(self.variable_mapping, f)
        # save final edge dictionary
        with open(os.path.join(path, "final_edge_dict.json"), "w") as f:
            json.dump(self.final_edge_dict, f)
        self.scm.scm_to_json("", os.path.join(path, "scm_simple.json"))

        # after saving the data, check if the data is informative, otherwise raise an error
        # check if the final_df_interactions has 0 variance in any columns
        # if yes, raise an error
        if self.final_df_interactions.columns[
            self.final_df_interactions.var() == 0
        ].any():
            sys.exit(
                "ZERO VARIANCE ERROR: The outcome variable has 0 variance and the SCM cannot be estimated. This means that the experiment is not informative. Please try a different set of variables. The raw data should still be saved for you to inspect as a reference."
            )


if __name__ == "__main__":
    # others that work but are less interesting/small sample 'mug_found''mug_1', auction_art_2vars
    dir_list = ["lawyer_interview_3var"]
    # dir_list = ['tax_fraud']snow_shovel
    path = "/Users/benjaminmanning/Library/CloudStorage/Dropbox/robot_scientist/data_for_paper/"
    for dir in dir_list:
        directory_path = path + dir + "/"
        raw_data = pd.read_csv(directory_path + "raw_data.csv")
        with open(directory_path + "meta_data.json", "r") as f:
            meta_data = json.load(f)
        with open(directory_path + "result.json", "r") as f:
            interaction_data = json.load(f)
        data_analyst = DataCleaner(interaction_data, raw_data, meta_data)
        data_analyst.generate_final_df()
        data_analyst.save_data(directory_path)
